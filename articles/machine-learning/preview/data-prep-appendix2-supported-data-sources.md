---
title: "Sources de données prises en charge disponibles avec la préparation des données Azure Machine Learning | Microsoft Docs"
description: "Ce document fournit la liste complète des sources de données prises en charge disponibles pour la préparation des données Azure Machine Learning."
services: machine-learning
author: euangMS
ms.author: euang
manager: lanceo
ms.reviewer: 
ms.service: machine-learning
ms.workload: data-services
ms.custom: 
ms.devlang: 
ms.topic: article
ms.date: 09/12/2017
ms.openlocfilehash: db4774de28a17e022de111986f72a1f15ec32beb
ms.sourcegitcommit: 295ec94e3332d3e0a8704c1b848913672f7467c8
ms.translationtype: HT
ms.contentlocale: fr-FR
ms.lasthandoff: 11/06/2017
---
# <a name="supported-data-sources-for-azure-machine-learning-data-preparation"></a>Sources de données prises en charge disponibles pour la préparation des données Azure Machine Learning 
Cet article présente les sources de données actuellement prises en charge pour la préparation des données Azure Machine Learning.

Les sources de données prises en charge pour cette version sont répertoriées ci-dessous.

## <a name="types"></a>Types 
### <a name="directory-vs-file"></a>Répertoire et fichier
Choisissez un fichier unique et lisez-le dans la préparation des données. Le type de fichier est analysé afin de déterminer les paramètres par défaut pour la connexion de fichiers affichée dans l’écran suivant.

Choisissez un répertoire ou un ensemble de fichiers contenus dans un répertoire (le sélecteur de fichiers permet d’effectuer plusieurs sélections). Quelle que soit l’approche utilisée, les fichiers sont lus en tant que flux de données unique, puis ajoutés les uns aux autres, les en-têtes étant supprimés si nécessaire.

Types de fichier pris en charge :
- Délimité (csv, tsv, txt, etc.)
- Largeur fixe
- Texte brut
- Fichier JSON

### <a name="csv-file"></a>Fichier CSV
Lisez un fichier de valeurs séparées par des virgules à partir du stockage.

#### <a name="options"></a>Options
- Séparateur
- Commentaire
- headers
- Symbole décimal
- Encodage de fichier
- Lignes à ignorer

### <a name="tsv-file"></a>Fichier TSV
Lisez un fichier de valeurs séparées par des tabulations à partir du stockage.

#### <a name="options"></a>Options
- Commentaire
- headers
- Encodage de fichier
- Lignes à ignorer

### <a name="excel-xlsxlsx"></a>Excel (.xls/.xlsx)
Lisez un fichier Excel, une feuille à la fois, en spécifiant le nom ou le numéro de la feuille.

#### <a name="options"></a>Options
- Nom ou numéro de la feuille
- headers
- Lignes à ignorer

### <a name="json-file"></a>Fichier JSON
Lire un fichier JSON à partir du stockage. Le fichier est « aplati » lors de la lecture.

#### <a name="options"></a>Options
- Aucun

### <a name="parquet"></a>Parquet
Lisez un jeu de données Parquet, fichier ou dossier unique.

Le format Parquet peut prendre différentes formes dans le stockage. Pour les jeux de données plus petits, un fichier .parquet unique est parfois utilisé. Différentes bibliothèques Python prennent en charge la lecture de fichiers .parquet uniques ou leur écriture. Pour le moment, la préparation des données Azure Machine Learning s’appuie sur la bibliothèque Python PyArrow pour la lecture de données Parquet lors de l’utilisation interactive locale. Elle prend en charge les fichiers .parquet uniques (à condition qu’ils soient écrits comme tels, et non dans le cadre d’un jeu de données plus grand), ainsi que les jeux de données Parquet.

Un jeu de données Parquet est une collection de plusieurs fichiers .parquet représentant chacun une partition plus petite d’un plus grand jeu de données. Les jeux de données sont généralement contenus dans un dossier, et constituent le format de sortie Parquet par défaut pour les plateformes telles que Spark et Hive.

>[!NOTE]
>Lors de la lecture de données Parquet qui se trouvent dans un dossier contenant plusieurs fichiers .parquet, il est plus sûr de sélectionner le répertoire pour la lecture et l’option **Parquet data set** (Jeu de données Parquet). Ainsi, PyArrow lira la totalité du dossier plutôt que chaque fichier. Cela garantit la prise en charge de la lecture de méthodes de stockage Parquet sur disque plus compliquées (par exemple le partitionnement de dossier).

L’exécution avec montée en puissance repose sur les capacités de lecture Parquet de Spark, et prend en charge les fichiers individuels et les dossiers, comme en mode interactif local.

#### <a name="options"></a>Options
- Jeu de données Parquet. Cette option détermine si la préparation des données Azure Machine Learning développe un répertoire donné et tente de lire chaque fichier individuellement (mode non sélectionné) ou si elle traite ce répertoire comme l’ensemble du jeu de données (mode sélectionné). Avec le mode sélectionné, PyArrow choisit la meilleure façon d’interpréter les fichiers.


## <a name="locations"></a>Emplacements
### <a name="local"></a>Local
Emplacement de stockage réseau mappé ou disque dur local.

### <a name="azure-blob-storage"></a>Stockage d'objets blob Azure
Stockage Blob Azure qui nécessite un abonnement Azure.

